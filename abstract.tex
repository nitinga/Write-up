Recommender systems, such as those found on Netflix and Amazon,
aggregate data across millions of users to make individualized product
suggestions. Each user provides some data about items he or she is
interested in, typically in the form of ratings or clicks, and the
system predicts ratings for unseen items by leveraging data from other
users. Thinking of users as rows and items as columns in a large
matrix, we can formalize these types of problems as \emph{matrix
completion} from a few observed entries. We provide working
implementations of two competing matrix completion algorithms,
Spectral Matrix Completion (SMC) and Singular Value Thresholding
(SVT), and evaluate them on both synthetic and real-world datasets. We
compare their performance against simple baselines, including
Eigentaste, k-nearest neighbors, and item mean. Our comparisons
demonstrate the differences in accuracy and time complexity of these
methods for many problem sizes and structures. All of the presented
methods have their own problem-dependent advantages and disadvantages.
However, in our evaluation on the real-world Jester jokes dataset, we
find that SMC and SVT greatly outperform Eigentaste, an algorithm
specifically designed to leverage special structure in the Jester
dataset. This performance boost likely comes from the fact that SMC
and SVT leverage more data overall when making predictions. Between
SMC and SVT, SMC provides better accuracy but is much slower than SVT.
