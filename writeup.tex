\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath}
\usepackage{graphicx}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{Singular Value Thresholding for Matrix Completion}


\author{
Sriram Ganesan\thanks{ The names are printed in alphabetical order by last name.} \\
\texttt{sriramg@umich.edu} \\
\And
Nitin Garg \\
\texttt{gargn@umich.edu} \\
\AND
Jeeheh Oh \\
\texttt{jeeheh@umich.edu} \\
\And
Jonathan Stroud \\
\texttt{stroud@umich.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
\input{abstract}
\end{abstract}

\section{Introduction}

Recovering a low rank matrix from a given subset of its entries is a well known problem in collaborative filtering \cite{r25} , dimensionality reduction\cite{r20, r28} and multi-class learning \cite{r2, r22}, finding the lowest rank matrix satisfying equality constraints is NP-hard. The complexity class of decision problems that are intrinsically harder than those that can be solved by a nondeterministic Turing machine in polynomial time. Examples of NP-hard problems include the Hamiltonian cycle and traveling salesman problems. All known algorithms which can compute lowest rank solution for all instances require time atleast exponential in the dimensions of the matrix in both theory and practice.

Candes and Recht showed that most low rank matrices could be recovered from most sufficiently large sets of entries by computing the matrix of minimum nuclear norm that agreed with the provided entries\cite{r4} and the known set of entries could comprise a vanishing fraction of the entire matrix. The nuclear norm is equal to the sum of the singular values of a matrix and is the best convex lower bound of the rank function on the set of matrices whose singular values are all bounded by 1. The intuition behind this measure is that whereas the rank function counts the number of nonvanishing singular values, the nuclear norm sums their amplitude, much like how the 1- norm is a useful substitute for counting the number of nonzeros in a vector. Moreover, the nuclear norm can be minimized subject to equality constraints via semidefinite programming.

Nuclear norm minimization had long been observed to produce very low-rank solutions in practice (see, for example \cite{r11, r12, r26}), but only very recently was there any theoretical basis for when it produced the minimum rank solution. The first paper to provide such foundations was \cite{r24}, where Recht, Fazel, and Parrilo developed probabilistic techniques to study average case behavior and showed that the nuclear norm heuristic could solve most instances of the rank minimization problem assuming the number of linear constraints was sufficiently large. The results in \cite{r24} inspired a groundswell of interest in theoretical guarantees for rank minimization, and these results lay the foundation for \cite{r4}. Candes and Recht’s bounds were subsequently improved by Candes and Tao \cite{r7} and Keshavan, Montanari, and Oh \cite{keshavan2010matrix} to show that one could, in special cases, reconstruct a low-rank matrix by observing a set of entries of size at most a polylogarithmic factor larger than the intrinsic dimension of the variety of rank r matrices.

\emph{Collaborative Filtering} is the process of learning patterns by
aggregating information over multiple sources of data, typically
multiple users of the same system. These techniques have been applied
effectively on many difficult problems, most notably on recommender
systems such as those found on Netflix, Amazon, Spotify, and others.
The goal of these systems is to produce targeted product
recommendations for individual users given the products the user has
previously viewed or rated. Users have typically viewed or rated only
a small subset of the available products, and different users
typically have not rated the same set of products. These problems do
not easily lie into any supervised learning framework, so we instead
employ the framework of \emph{matrix completion}.

In matrix completion, we reconstruct a matrix $M$ from a set of known
entries $M_{ij}, \ (i,j) \in \Omega$. Relying on the assumption that
$M$ has low rank, we can pose this as a constrained rank-minimization
problem
\begin{equation*}
\begin{aligned}
  & \underset{X}{\text{minimize}} & & \mathrm{rank}(X) \\
  & \text{subject to}             & & X_{ij} = M_{ij}, \ \ \forall (i, j)
  \in \Omega. \\
\end{aligned}
\end{equation*}

In this project, we explore several algorithms for matrix completion
via rank-minimization and compare their performance on collaborative
filtering baselines. We provide an implementation of the method
described in ``A Singular Value Thresholding Algorithm for Matrix
Completion'' \cite{cai2010singular} and reproduce their experiments.
We also provide an implementation of a competing algorithm from
``Matrix Completion from a Few Entries'' \cite{keshavan2010matrix} and
compare their effectiveness.



\section{Singular Value Thresholding}

Singular Value Thresholding (SVT) \cite{cai2010singular} is an
algorithm proposed for \emph{nuclear norm minimization} of a matrix.
Formally, SVT addresses the optimization problem
\begin{equation*}
\begin{aligned}
  & \underset{X}{\text{minimize}} & & \|X\|_{*} \\
  & \text{subject to}             & & \mathcal{P}_\Omega (X) =
  \mathcal{P}_\Omega (M), \\
\end{aligned}
\end{equation*}
where $\|\cdot\|_{*}$ is the \emph{nuclear norm}, or the sum of the
singular values and $\mathcal{P}_\Omega (\cdot)$ makes zero all
entries $(i, j) \notin \Omega$. This can be thought of as a convex
relaxation to the rank minimization problem, and the two are formally
equivalent under some conditions. The rank minimization problem is,
however, highly non-convex and therefore not a suitable candidate for
black-box optimization algorithms.

Singular Value Thresholding works by iteratively constructing $X$
using a low-rank, low-singular value approximation to an auxiliary
sparse matrix $Y$. $Y$ is then adjusted to ensure the resulting
approximation in the subsequent step has matching entries
$X_{ij} = M_{ij}$. Each iteration consists of the inductive steps
\begin{equation*}
\begin{cases}
X^{k} = \mathrm{shrink}(Y^{k-1}, \tau) \\
Y^{k} = Y^{k-1} + \delta_k \mathcal{P}_\Omega (M-X^{k}),              \\
\end{cases}
\end{equation*}
where $\mathrm{shrink}(\cdot, \cdot)$ is the \emph{singular value
  shrinkage operator}. Given a singular value decomposition $X = U
\Sigma V^T$, $\Sigma = \mathrm{diag}(\{\sigma_i\}_{1 \le i \le r})$, we
  can write this as
\begin{equation*}
\mathrm{shrink}(X, \tau) = U\Sigma_\tau V^T, \ \ \Sigma_\tau = \mathrm{diag}(\{(\sigma_i-\tau)_{+}\}).
\end{equation*} 

These two operations, when repeated, approach a low-nuclear norm
solution by repeatedly shrinking the singular values of X. This
algorithm has shown success in recovering accurate low-rank solutions
when the source of $M$ is also low-rank, even though it does not
optimize this objective directly. The original authors discuss its
theoretical guarantees in detail, but we choose to omit them in this
discussion.

In practice, this system has a number of hyperparameters that must be
carefully tuned to guarantee convergence. The shrinkage value $\tau$
must be set fairly high in order for the algorithm to converge
quickly, but not too high that it dwarfs the true singular values. The
stepsizes $\delta_k$ are similarly sensitive. These can be set
dynamically as well, though we choose to maintain a fixed stepsize
throughout. We compute the decomposition of $Y^K$ in batches, which
introduces a new batch size parameter $l$. Also important is the
initialization of $Y^0$, for which the authors provide helpful
strategies. Finally, we use the relative error
$\|\mathcal{P}_{\Omega}(X^k-M)\|_F / \|P_{\Omega} (M)\|$ as a stopping
criterion. We terminate when this drops below a small $\epsilon$.

\section{Spectral Matrix Completion}

\input{smc}


\section{Baseline Algorithms}

\subsection{Eigentaste}

Eigentaste is a collaborative filtering algorithm which applies
principal component analysis to the dense subset of user ratings, thus
facilitating dimensionality reduction for offline clusters and rapid
computation of recommendations. Mean rating of the jth item in the
gauge set is given by
\begin{equation*}
\mu_{ij}=\frac{1}{n}{\sum_{i\epsilon U_{j}}}\widetilde{r}_{ij}\\
\end{equation*}
\begin{equation*}
\sigma_j^2=\frac{1}{n-1}{\sum_{i\epsilon U_{j}}}({\widetilde{r}_{ij}-\mu_{j}})^{2}
\end{equation*}

In A, the normalized rating $r_{ij}$ is set to
$({\widetilde{r}_{ij}-\mu_{j}})/\sigma _{j}$ . The global correlation
matrix is given by
\begin{equation*}
C=\frac{1}{n-1}A^{T}A=E^{T} \Lambda E
\end{equation*}

The data is projected along the first v eigenvectors $x=R{E_{v}}^{T}$

\textit{Recursive Rectangular Clustering: }

\begin{enumerate}
\item Find the minimal rectangular cell that encloses all the points
  in the eigenplane.
\item Bisect along x and y axis to form 4 rectangular sub-cells.
\item Bisect the cells in step 2 with origin as a vertex to form
  sub-cells at next hierarchial level.
\end{enumerate}

 \textit{Online Computation of Recommendations}

\begin{enumerate}
\item Collect ratings of all items in gauge set.
\item Use PCA to project this vector to eigenplane.
\item Find the representative cluster.
\item Look up appropriate recommendations, present them to the new
  user, and collect ratings.
\end{enumerate}

\subsection{K-Nearest Neighbor}
Nearest neighbor algotihm predicts the ratings based on mean user rating and variation of the current rating from the mean rating of its nearest neighbors.
\begin{equation*}
p_{ij}=\overline{r_{i}}+\kappa\sum_{k=1}^n w(i,p)(\overline{r_{pj}}-\overline{r_{p}})
\end{equation*}
where $\overline{r_{i}}$ is the average joke rating for user i, and $\kappa$ is a
normalizing factor ensuring that the absolute value of the
weights sum to 1. We implemented the weighted nearest neighbor algorithm.
We used a function of Euclidean distance from
user i to user p as the weight w(i, p), and $\kappa$ = $\sum_{k=1}^n w(i,p)$.
Specifically, if we are interested in q nearest neighbors,
w(i; p) = d(i, q +1)- d(i, p). This ensures that i’s closest
neighbor has the largest weight.

\section{Experimental Results}
\subsection{Synthetic Data}
The performance of the SVT and SMC algorithms were compared on synthetically generated matrices of varying ranks, sizes and sparsity. Specifically, the algorithms were tested on all combinations of matrix size(1000, 5000), rank (5, 10 and 20), and sparsity(30\%, 50\% and 70\%). As a baseline to SVT and SMC, a column mean matrix completion method was implemented. This method predicts the average column value for all missing entries. 
In the Tables~\ref{MAE},~\ref{Time} the mean absolute error and the run time is averaged over the categories of size, rank and sparsity. For example, out of the eighteen tests that were run, nine tests include the matrix of size 1000x1000. Therefore the mean absolute error value for all nine tests are averaged in order to represent the values in the size 1000 column of the table below. Mean absolute error is the absolute value of the average error on the unknown entries. Run time is measured in seconds and all simulations were run at University of Michigan's CAEN lab computers (8GB memory with one core i7 processors). The columns in Tables~\ref{MAE},~\ref{Time} contain the averaged mean absolute error and the run time for all experiments.

\begin{table} [ht!]
\centering
 \caption{Mean Absolute Error}
 \begin{tabular}{l @{\hspace{12pt}}| l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}|l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}|l @{\hspace{12pt}}l @{\hspace{12pt}}}% p{2cm}}
  \hline \hline
   & &\text{Rank}  & &  &\text{Sparsity}&& \text{Size} & \text{(Average)} \\
\text{Algorithm} & 5 & 10 & 20 & 30\% & 50\% & 70\% & 1000 & 5000 \\
\hline
\text{Mean}  & 5.65 & 9.90 & 13.98 & 9.10 & 10.21 & 10.21 & 9.43 & 10.26\\
\text{SVT}  & 2.05 & 7.2E-04 & 1.4E-03 & 2.05 & 8.4E-04 & 9.6E-04 & 1.37 & 7.6E-04\\
\text{SMC} & 2.1E-04 & 4.3E-07 & 4.5E-07 & 2.1E-04 & 4.2E-07 & 3.8E-07  & 1.4E-04 & 3.7E-07\\
 \hline \hline
\label{MAE}
 \end{tabular}
\end{table}

\begin{table} [ht!]
\centering
 \caption{Run Time (in seconds)}
 \begin{tabular}{l @{\hspace{12pt}}| l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}|l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}|l @{\hspace{12pt}}l @{\hspace{12pt}}}% p{2cm}}
  \hline \hline
  & &\text{Rank}  & &  &\text{Sparsity}&&\text{Size} & \text{(Average)} \\
\text{Algorithm}& 5 & 10 & 20 & 30\% & 50\% & 70\%  & 1000 & 5000 \\
\hline
\text{Mean}  & 0.12 & 0.12 & 0.10 & 0.11 & 0.11 & 0.12 & 0.01 & 0.22\\
\text{SVT} & 26 & 39 & 92 & 42 & 54 & 60& 6 & 98 \\
\text{SMC}& 252 & 405 & 1623 & 1021 & 510 & 748 & 86 & 1433 \\
\hline \hline
\label{Time}
 \end{tabular}
\end{table}

Both SVT and SMC outperform the baseline column-mean method. In addition, SMC consistently outperforms SVT in terms of mean absolute error, by order of three. While SMC significantly outperforms SVT in terms of accuracy, SVT significantly outperforms SMC in terms of time.  It appears that the computational cost of SMC grows exponentially with rank size. Even at rank five, the smallest tested rank value, SMC runs 9.6 times slower than SVT. 

% I put this table in a separate file because it is auto-generated by
% a script. I'll clean it up later once I finish running the
% experiments - Jonathan
%\input{tables/svt_synth.tex}

\subsection{Real Datasets}
The Jester joke dataset contains 4.1 million rating for 100 jokes from 73,421 users~\cite{r30}. 

For the purpose of comparison between different algorithms, namely SMC, SVT, and Eigentaste (as baseline), {100, 200, 1000} users are selected at random.  Two ratings at random from each user is selected as a test set and the Normalized Mean Absolute Eroor (NMAE) is compared in this set (similar to presented in~\cite{oh2010thesis}. The NMAE is a commonly used performance metric in collaborative filtering. The Mean Absolute Error (MAE) is define as:
\begin{equation}
MAE = \frac{1}{|T|}\sum\limits_{(u,i) \in T} |M_{ui} - \widetilde{M}_{ui}|
\end{equation}
where $M_{ui}$ is the original ratings, $\widetilde{M}_{ui}$ is the predicted rating for user $u$, item $i$, and $T$ is the test set. Then, the NMAE can be defined as:
\begin{equation}
NMAE = \frac{MAE}{M_{max}-M_{min}}
\end{equation}
where $M_{max}$ and $M_{min}$ are the upper and lower bounds for the ratings. In the Jester joke dataset, the rating are in [-10,10].
%\begin{figure}[h!]
%\centering
%\includegraphics[trim=0 0 0 0, clip, width=1.0\linewidth]{eigentaste_jester.tiff}
%\caption{\footnotesize Figure shows the comparison between the original NACA 0009, undeformed multipoint hydrostructural optimized foil, and deformed multipoint hydrostructural optimized foil at $C_L = 0.65$. Figure also shows the zoomed-in view of the trailing edge thickness at the root. Note the increased thickness for the multipoint optimized foil at the root to meet the stress constraints for the higher loading cases. The trailing thickness of the optimized foil is higher than the original NACA 0009 foil, can also be noted. The results are obtained using the RANS solver with $Re= 1.0 \times 10^6$ and $V = 12.4$ m/s. }
%\label{Geo}
%\end{figure}

In the Table~\ref{SMC}, numerical results on the Jester joke dataset with SMC algorithm is presented. The number of jokes are fixed at 100 and number of users were varied as {100, 200, 1000}. The NMAE is calculated as shown earlier and CPU time is presented as the time (in seconds) on University of Michigan's CAEN lab computer(8GB memory with one core i7 processors).

\begin{table} [h]
\centering
 \caption{Numerical results on the Jester joke dataset with SMC algorithm}
 \begin{tabular}{l @{\hspace{12pt}} l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}}% p{2cm}}
  \hline \hline
  \text{ num. user} & \text{num. jokes} &\text{samp. ratio}  & \text{NMAE}&\text{Time (in sec.)}\\
\hline
100 & 100 & 5353 & 0.1573 & 25.31\\
200 & 100 & 10921 & 0.1603 & 17.44\\
1000 & 100 & 57578 & 0.1647 & 44.95\\
\hline \hline
\label{SMC}
 \end{tabular}
\end{table}

These 10 dense columns becomes very critical for some algorithms, such as Eigentaste.

\begin{table} [h]
\centering
 \caption{NMAE comparison on the Jester joke dataset for SMC, SVT, and Eigentaste algorithm}
 \begin{tabular}{l @{\hspace{12pt}} l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}l @{\hspace{12pt}}}% p{2cm}}
  \hline \hline
 & & & \text{NMAE} &\\
  \text{ num. user} & \text{num. jokes} &\text{SMC}  & \text{SVT}&\text{Eigentaste}\\
\hline
100 & 100 & 0.1573 & 0.1865 &0.187\\
200 & 100 & 0.1603 & 0.1843 & 0.190\\
1000 & 100 & 0.1647& 0.1714 & 0.237\\
\hline \hline
\label{Compare}
 \end{tabular}
\end{table}

We have eigentaste, SMC and SVT on subsets of the Jester dataset.
Compare accuracy and time. 
Mention that we used LMSVD in SMC for this version.

\section{Conclusions}

General Points:
synthetic data conclusions: SMC and SVT are better than baseline mean method.
SMC attains better accuracy than SVT but takes longer.
One potential improvement to SMC is to use the LMSVD mentioned in the SVT paper. 
We used this upgrade in the Jester dataset tests and we found that 



\section{Group Member's Accomplishments}
All team members participated in data processing early in the project.
All team members contributed to the final report. Each member was responsible for the
writeup regarding their individual experiments.
Sriram spearheaded the eigentaste approach. He discovered ways of modifying these methods
to supercharge performance and he also contributed a great deal towards the performance metric for different algorithms.
Nitin and Jeeheh implemented the SMC algorithm. Jeeheh took charge in getting the performance comparison for the synthetic data. Nitin contributed towards the performance metric for different algorithms and also helped integrating the final report together.
Jonathan was in command of the SVT algorithm. SVT algorithm lot of parameter tuning too. He also created those nice-looking visulaization plots in the report.


\bibliographystyle{plain}
\bibliography{writeup}

\end{document}
